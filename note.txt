1. Peer si iscrive al Registry
2. Registry aggiunge i Peer tra i nodi
3. Registry aggiunge il nodo al grafo dei nodi e sceglie a caso dei vicini da dire al Peer (assicurando che ne venga preso almeno 1)
4. Registry risponde al Peer indicando a quali vicini connettersi
5. Peer si connette ai vicini che il Registry gli ha detto
    5_1. Se un vicino non risponde il Peer lo trascura e basta

1. Periodicamente il Registry controlla il Grafo della rete
2. Se il grafo è connesso bene
3. Se il grafo non è connesso
    3_1. Data la lista delle componenti connesse, prendi due componenti consecutive
    3_2. Per ogni nodo della prima componente connettilo in maniera casuale con i nodi dell'altra, garantendo che almeno un arco sia creato
    3_3. La creazione della connessione è fatta chiamando un metodo del Peer
    3_4. Aggiorna il grafo delle connessioni

1. Periodicamente il Registry controlla se ci sono dei peer che non rispondono ad un segnale di Ping
2. Se non risponde allora lo rimuove dal grafo dei peer e chiude la connessione che aveva aperto verso di lui

TODO Politica di Peer / Heartbeat: se usiamo Heartbeat possiamo implementare una politica di ripresa del server dal Peer
TODO Cosa succede se una richiesta non viene soddisfatta (non arriva la risposta)

TODOS:
1. Tracciare percorso della richiesta
2. Fare attenzione che non ci sia risposta multipla (dagli edge verso l'edge richiedente)
3. Se l'edge richiedente non ha spazio? cancello le più vecchie...
4. ok ma se il file è più grande dell'intera cache? --> invio il link s3 
5. numero di hop della richiesta in log(N) impostando una treshold massima
6. se ho il file lo mando indietro al primo edge richiedente -->  nei metadati mantengo solo il primo
8. identificativo richiesta per non rielaborare più volte --> coda per le richieste


IDEE:
storage partizionato --> 30MB cache / 70MB dati (NB: se file 80MB invio comunque il link S3) 

LOGICA CACHING:
popolarità --> Come la gestiamo? --> Coda di popolarità (?)

EXCHANGE?
(per avere concetto di popolarità generale --> la coda rabbit fa load balancing, la popolarità locale sarebbe limitante)
Il registry potrebbe dire all'edge appena entrato di quali topic si occupa 
costruendo le code con hashing del nome (so già a chi chiedere) --> problema: andrebbe fatto scalabile a run-time rispetto a quanti file con quel nome hai

Difficile da implementare (?)

PUT (?):
9. l'edge che riceve una PUT manda un messaggio di richiesta file al client con id della richiesta corrispondente e info per contattarlo
10. if fileSize > 70MB {nei metadati della PUT và inserita la dimensione del file} --> redirected directly to s3
11. if fileSize > 4MB (maxMessageSize) --> need multiple messages (chunked files)
12. if fileSize < 70MB but fileSize > current free edge memory --> ask to neighbours if they can store it

SOLUZIONE GET/PUT --> IL CLIENT ESPONE UN SERVIZIO PER RICEVERE/INVIARE IL FILE DAL PRIMO EDGE DISPONIBILE A FORNIRGLIELO
nei metadati: indirizzi dove contattare il CLIENT. l'edge fa l'ack sulla coda solo dopo aver contattato il client e aver eseguito lo scambio.


Buonasera professore, sono Manenti Edoardo uno studente del corso di SDCC del primo anno di magistrale. 
Non avendo la traccia del progetto (La docente ancora non ce ne ha fornita una versione ufficiale/completa) con i miei colleghi abbiamo cominciato a pensare a qualche soluzione da applicare per realizzare l'architettura del sistema.
Il titolo della traccia è "Storage nel Cloud Edge Continuum" ovvero la traccia A1 tra i progetti proposti dalla professoressa Cardellini.
L'architettura a cui avevamo pensato è quella visibile nella figura1 in allegato (in particolare nel contesto di una GET su file).

Per intenderci:
- Abbiamo il Client che inoltra delle richieste ad una message queue (abbiamo pensato a rabbitMQ) 
- Lato Server invece abbiamo una rete non strutturata di Edge e un Registry.
- Il Registry gestisce iscrizione e uscita degli Edge dalla rete (abbiamo pensato anche ad un controllo periodico delle componenti connesse del grafo di Edge per evitare partizionamento di rete)
- Gli Edge gestiscono le richieste lette dalla coda. 
- Quando un Edge riceve una richiesta, controlla se possiede/gestisce quel file:
    Nel caso lo possieda, inoltra al Client direttamente (siamo indecisi se utilizzare FTP o gRPC dividendo eventualmente il file in chunk se troppo grande)
    Altrimenti, inizia una ricerca inoltrando la richiesta ai suoi vicini.
    NB|: per evitare flooding all'interno della rete abbiamo pensato di far scambiare ai nodi vicini dei filtri di Bloom che riassumano i file che ogni nodo possiede in modo da limitare la ricerca soltanto ai vicini che rispondono positivamente al controllo sui filtri
    Quando un nodo che riceve la richiesta inoltrata possiede quel file, lo inoltra all'edge richiedente (il primo nella catena per ridurre latenza a discapito dell'efficienza del meccanismo di caching --> anche qui non siamo sicuri della scelta non conoscendo il dominio di applicazione e in assenza della traccia)
    A quel punto l'edge richiedente lo salva a sua volta (caching) e lo invia al Client
    NB|: Se il file non è trovato nella rete, viene contattato S3 per scaricarlo e inviarlo al Client
- Se la coda rabbitMQ non risponde, il Client si rivolge direttamente ad S3
- Per evitare che la coda rabbitMQ sia un SPOF facendo delle ricerche abbiamo trovato le "quorum queues" basate su Raft per aumentare la tolleranza ai guasti (anche qui non sappiamo se è fuori dalla portata del progetto o può essere una buona soluzione)
- Un altra idea è quella di partizionare le code rabbitMQ rispetto a determinati topic (es: hashing sul nome del file)

Queste erano le idee principali, partendo da queste sono sorti dei problemi riguardo le implementazioni della PUT e della DELETE (non che nelle idee appena elencate ci sia un qualche grado di sicurezza non avendo come ripeto alcuna traccia su cui basarci)

I problemi riguardanti la PUT sono:
- Se eseguire la PUT direttamente dal Client su S3 sia una buona idea o non sia contro la natura del progetto 
- Altrimenti, se dobbiamo passare per la rete di Edge che, come ci ha detto la professoressa in classe, hanno risorse limitate... quando un file è troppo grande come lo gestiamo?
    ad esempio... se l'Edge che ha ricevuto la richiesta non è in grado di memorizzare il file (fileSize > edgeMemorySize or fileSize > currentFreeMemoryInEdge) 
        - cerca altri Edge che possono memorizzarlo (supponendo che ci siano Edge con size di memoria differente) ?
        - fa da ponte direttamente con S3 ?
        - dice al client che deve contattare S3 ? E nel caso lo fa solo dopo che la ricerca di altri Edge ha fallito ?

Il problema principale riguardante la DELETE, visto il meccanismo di caching dei file popolari o piccoli, come ci assicuriamo che il file venga eliminato?
    anche qui abbiamo pensato a diverse possibilità:
        - implementare un meccanismo periodico da parte degli Edge come una sorta di "pull" da S3 dei metadati riguardanti la presenza o l'assenza dei file mantenuti in cache/memoria nel Cloud
        NB|: ma anche in quel caso, dopo essersi resi coerenti con S3 (ad esempio eliminando il file), se il file è molto popolare una successiva ricerca potrebbe nuovamente riportarlo in cache se un altro Edge ancora non lo ha eliminato
        - usare in qualche modo anche in questo contesto i filtri di bloom per propagare l'informazione
        - applicare flooding (ma anche qui una nuova ricerca potrebbe essere più veloce e dare lo stesso problema di cui sopra)

L'alternativa a tutto ciò sarebbe una rete strutturata [ aka Chord :) ] che renderebbe sovrabbondanti i filtri di bloom e semplificherebbe le operazioni.
Ovviamente non ci siamo buttati su Chord dato che ci sovrapporremmo con un'altra traccia e si tratterebbe soltanto di aggiungerci sopra S3.

In qualsiasi caso senza alcuna traccia "E' come cercare di trattenere l'acqua con le mani aperte." -cit ChatGPT

Spero che lei possa darci qualche indicazione o possa aiutarci a metterci in contatto con la professoressa Cardellini.
In attesa di un suo riscontro le auguro una buona serata. Cordiali Saluti