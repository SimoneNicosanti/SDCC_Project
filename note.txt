=========================================
RAGIONIAMO
=========================================
1] rete p2p non strutturata con nuove connessioni probabilistiche e casuali (Erdős–Rényi model) --> OK
2] procedura di login e gestione su nome file --> OK
        - database chiave valore REDIS per gestire le utenze
        - nome utente accodato al nome del file nella put (nella get richiedere file con 'nomeFile_utenteX')
3] filtri di bloom ricerca nella rete --> OK
4] la rete di edge fa caching (si appoggia di base su S3) --> OK
5] interfaccia CLI --> OK
6] meccanismo heartbeat al registry + comunica num connessioni --> OK
7] meccanismo ping edge-edge --> OK
8] build graph periodico da parte del registry (pull sulle info sui neighbours + calcolo componenti connesse ed eventuale unificazione) --> OK
9] timer sulle chiamate goRPC (evitiamo freeze della rete se succede qualcosa su un edge) --> OK
10] meccanismo di caching in memory (tmpfs da 100MB) popularity based + threshold sulla dimensione dei file --> OK
11] DOMINIO DI APPLICAZIONE (necessità, caratteristiche, richieste su prestazioni/risorse etc etc...) --> DECIDETE VOI --> IoT devices in same organization / Global storage service (algoritmo vivaldi)
12] quali sono le risorse limitate e come limitarle --> TUTTE QUELLE POSSIBILI (raspberryPI systems)
    -bisogna limitare:
        > CPU / MEMORIA --> cpu e memoria con docker 
13] ricerca file hop by hop senza caching --> OK, se locale
14] consistenza in generale + come gestire la cancellazione "distribuita" di un file: (NB: stabilire il livello di consistenza che si vuole raggiungere)
        IDEA: countdown_to_deletion su singolo file --> consistenza finale / nessuno scambio / unico costo è quello eventualmente di riaggiungerlo se fosse popolare (aiuta anche a resettare la popolarità)
15] timestamp su file / username con login / ibrido (pubblico/privato) --> a seconda delle assunzioni
        IDEA: sistema locale ma storage pubblico --> login (versioning solo tra i vari "client") 
                es: sensore 2 usa file di sensore 6 allora lui sa che deve richiedere "get pump_data_u6.csv" --> ogni user è responsabile del versioning dei suoi file
16] testing:
        test rispetto a situazione di base (solo cloud)
        test molte get / test intermedio / test molte put (box plot su tempi di risposta)
        test su scale differenti (EC2 o locale al variare del numero di nodi edge es: una decina di edge)
        come i parametri di configurazione influenzano le prestazioni


============================================
TODO TODO TODO TODO TODO TODO TODO TODO TODO
============================================
x] ragionare sul problema del notify job end
N-1] testing
        test rispetto a situazione di base (solo cloud)
        mix variabile (configurabile) in cui ho localmente una percentuale dei file richiesti 
                (in cache, il resto dei file sono negli altri nodi edge così evitiamo di contattare il cloud evitando il BUG)
                e farlo variando dimensione di file e percentuale di località dei file

        test molte get (nel modo che abbiamo appena detto) / test intermedio / test molte put (box plot su tempi di risposta)
        locale al variare del numero di nodi edge es: una decina di edge
        come i parametri di configurazione influenzano le prestazioni
N] inventare storiella per presentare (sistema di sensori IoT (?)) + PRESENTAZIONE
N+1] risolvere ultimi TODO e pulizia codice (e.g. mettere lettere piccole a metodi che non vanno esportati / commentare sopra metodi cosa fanno)


============================================
NOVITA
============================================
aggiunta load balancer al posto della coda rabbit
aggiunta operazione di delete distribuita
cambiata gestione cache (concetto di popolarità introdotto + rimozione efficiente + rimozione periodica dopo tot tempo che aiuta anche con consistenza finale)
        - c'è sempre possibilità che gli edge si rimbalzino il file e che non si raggiunga consistenza finale (contattare s3 ogni volta non sarebbe ottimale)
        - ma MOOOOOOLTO raro... forse ha poco senso preoccuparsene (delete distribuita + cancellazioni periodiche + ...)
lookup aggiornata (aggiunta di lookup_server per contatto diretto per la risposta + risultati multipli per backup)
client ripiega autonomamente su S3 nel caso di fallimento del sistema
procedura di login nel load balancer che si appoggia a redis --> identificazione file come 'file_username'
        - redis esegue sullo stesso nodo del load balancer, va bene?
se il nodo da cui scarichiamo un file di grandi dimensioni subisce una failure noi lo riscarichiamo dall'inizio da un edge di backup che ci aveva risposto correttamente
        - oltretutto se non facessimo così e il file cambia non gestendo il versioning si mischierebbero due file

ISSUE SU GITHUB NON RISPOSTA... come facciamo i test?

PROBLEMA NOTIFY JOB END
        IDEA_1: Quando il load balancer restituisce un edge al client, creo anche una connessione load_balancer <-> edge per comunicare se effettivamente
                sia stato contattato o meno. Creo un timer su questa connessione per attendere una notifica da parte dell'edge che la manda solo se il client
                lo contatta. 
                MA --> pesante ma almeno non crescono all'infinito
        IDEA_2: Basarsi sempre su ciò che dice l'edge nell'heartbeat 
                MA --> se mi segno x > y richieste dove y è quello che ho ricevuto nell'hearbeat rischio di sovraccaricare fino al prossimo heartbeat
        ALTRIMENTI COME FARE?
                meccanismo pesato sulle due informazioni --> media pesata sui due valori.